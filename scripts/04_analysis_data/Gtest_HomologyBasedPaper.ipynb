{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetExpectedProbability(counts:pd.DataFrame, ax:int) -> pd.Series:\n",
    "    \n",
    "    '''\n",
    "    This functions computes the expected values shown as probabilities given a contingency table\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    counts: pd.DataFrame\n",
    "        Pandas DataFrame containing the counts of each group\n",
    "    \n",
    "    ax: int\n",
    "        Integer 0 or 1 indicating along which axis will be used to compute the expected value\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    \n",
    "    pd.Series: pandas Series indicating the probabilities for every group\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    total_sums = counts.sum(axis=ax)\n",
    "    \n",
    "    return total_sums / total_sums.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryMetrics(A:set,B:set) -> pd.DataFrame:\n",
    "\n",
    "    '''\n",
    "    \n",
    "    This function computes the True positives (TP), False Negatives (FN) and False Positives (FP)\n",
    "    from the comparation between the interactions found in two networks\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    A: set\n",
    "        Reference set to calculate True Positives (TP) and False Negatives (FN) \n",
    "    \n",
    "    B: set\n",
    "        Complement set to calculate True Positives (TP) and False Positives (FP)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "        pd.DataFrame: A data frame containing the TP, FP, FN of the networks compared\n",
    "\n",
    "    '''\n",
    "\n",
    "    TP = len(A.intersection(B))\n",
    "    FP = len(B.difference(A))\n",
    "    FN = len(A.difference(B))\n",
    "\n",
    "    df = pd.DataFrame([TP,FP,FN]).rename({0:\"Counts\"}, axis=1)\n",
    "    df.index = [\"TP\", \"FP\", \"FN\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetContingencyTable(reference:pd.DataFrame, n:int=10000) -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function get the contingency table (TP, FP, FN) from a random network obtained\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    reference: pandas DataFrame\n",
    "        Network containing columns \"TF\" (Transcription factors) and TG (Target gene). Every pair of values \n",
    "        TF-TG will describe an interaction\n",
    "    \n",
    "    n: int; default 10000\n",
    "        Number of random networks to retrieve (experiments)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    pd.DataFrame: A pandas data frame containing the counts of TP, FP, FN for every experiment\n",
    "    \n",
    "    '''\n",
    "\n",
    "    print(f\"Getting contingency table with n={n}\")\n",
    "    \n",
    "    random_contingency_table = pd.DataFrame(dtype=int, index=[\"TP\",\"FP\",\"FN\"])\n",
    "    number_of_interactions = New_network.shape[0]\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    for experiment in range(n):\n",
    "\n",
    "        print(f\"\\tExperiment: {experiment + 1}\", end=\"\\r\")\n",
    "        experiment = \"rand_\" + str(experiment)\n",
    "        random_df = reference.copy()\n",
    "\n",
    "        # If we do not transfor into a list, then the data frame matches the rows by index\n",
    "        # and the shuffle effect is lost \n",
    "    \n",
    "        random_df[\"TF\"] = random_df[\"TF\"].sample(number_of_interactions).to_list()\n",
    "\n",
    "        Interactions_sample = set(random_df[[\"TF\",\"TG\"]].apply(\" | \".join, axis=1))\n",
    "        metrics = BinaryMetrics(Interactions_known, Interactions_sample)[\"Counts\"]\n",
    "        random_contingency_table = pd.concat([random_contingency_table, metrics.rename(experiment)], axis=1)\n",
    "\n",
    "    end = time()\n",
    "    print(f\"\\tExperiment: {n}\")\n",
    "    print(f\"\\tThis functions took {end - start} secs to run\")\n",
    "    \n",
    "    return random_contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterNetworks(graph:pd.DataFrame) -> \"(known = pd.DataFrame, new = pd.DataFrame)\":\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function filters the \"Known\" and \"New\" (a.k.a inferred) interactions between two networks given\n",
    "    a specific format\n",
    "    \n",
    "    Parameters\n",
    "    \n",
    "    graph: pandas dataFrame\n",
    "        A pandas dataframe containing the whole network\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    (known = pd.DataFrame, new = pd.DataFrame): A two dimention tuple containing the known interactions\n",
    "        and the new interactions filtered\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(\"Filtering networks\")\n",
    "    \n",
    "    know_net = graph.query(\"STATUS == 'Known'\")\n",
    "    mask_new_cond_1 = graph[\"STATUS\"] == \"New\"\n",
    "    mask_new_cond_2 = (graph[\"STATUS\"] == \"Known\") & ((graph[\"ORG_REF\"] != \"NOT_REFR_ORG\") | (graph[\"TU_UNIT\"] != \"NOT_TU_REFER\")) \n",
    "\n",
    "    new_net = graph[mask_new_cond_1 | mask_new_cond_2]\n",
    "\n",
    "    return (know_net, new_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListDirectory(path:str, filter:bool=False) -> \"list\":\n",
    "    \n",
    "    '''\n",
    "    This function list the file names found inside a directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    path: str\n",
    "        String describing the path of the target directory\n",
    "    \n",
    "    filter: str or RegEx, default: False\n",
    "        String or RegEx instruction matching with the target file names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    list: list containing the file names\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(f\"Path directory: {path}\")\n",
    "    print(f\"Filter: {filter}\\n\")\n",
    "    \n",
    "    file_names = pd.Series(os.listdir(path))\n",
    "    \n",
    "    if filter:\n",
    "        file_names = file_names[file_names.str.contains(f\"{filter}\")]\n",
    "    \n",
    "    return list(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadParserNet(file:str, **kwargs) -> \"pd.DataFrame\":\n",
    "    \n",
    "    '''\n",
    "    This function load into a pandas DataFrame the specified network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    file: str\n",
    "        String describing the file name\n",
    "        \n",
    "    **kwargs:\n",
    "        Aditional named keys for the pd.read_csv object\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    pd.DataFrame: Pandas DataFrame with the network loaded\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    print(f\"Loading file: {file}\")\n",
    "    \n",
    "    return pd.read_csv(file, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path directory: ../IIMAS_V4/net/results_plus_TU\n",
      "Filter: ^GCF\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000195955.2_ASM19595v2_M_tuberculosis_H37Rv_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 1172.5626637935638 secs to run\n",
      "Tests:\n",
      "\tchi:19851.929906928002; p:0.0\n",
      "\tG:8508.405559605082; p:0.0\n",
      "\tGd:8508.405559605082; p:0.0\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000009045.1_ASM904v1_B_subtilis_168_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 867.7725138664246 secs to run\n",
      "Tests:\n",
      "\tchi:36266.04720884251; p:0.0\n",
      "\tG:11012.8756506352; p:0.0\n",
      "\tGd:11012.8756506352; p:0.0\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000009645.1_ASM964v1_S_aureus_N315_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 811.0757734775543 secs to run\n",
      "Tests:\n",
      "\tchi:4091.437905900494; p:0.0\n",
      "\tG:1768.8792048941998; p:0.0\n",
      "\tGd:1768.8792048941998; p:0.0\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000006765.1_ASM676v1_P_aeruginosa_PA01_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 886.6554882526398 secs to run\n",
      "Tests:\n",
      "\tchi:13531.05665515777; p:0.0\n",
      "\tG:3876.368825722836; p:0.0\n",
      "\tGd:3876.368825722836; p:0.0\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000006945.2_ASM694v2_S_enterica_LT2_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 927.5310921669006 secs to run\n",
      "Tests:\n",
      "\tchi:33034.29438524459; p:0.0\n",
      "\tG:12266.10701251166; p:0.0\n",
      "\tGd:12266.10701251166; p:0.0\n",
      "\n",
      "Loading file: ../IIMAS_V4/net/results_plus_TU/GCF_000005845.2_E_coli_K12_genomic_extended_network_plus_TU.txt\n",
      "Filtering networks\n",
      "Getting contingency table with n=10000\n",
      "\tExperiment: 10000\n",
      "\tThis functions took 1174.5114796161652 secs to run\n",
      "Tests:\n",
      "\tchi:40974.087732511725; p:0.0\n",
      "\tG:15288.18080803751; p:0.0\n",
      "\tGd:15288.18080803751; p:0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Listing and saving file names of the networks\n",
    "    network_path = \"../IIMAS_V4/net/results_plus_TU\"\n",
    "    network_file_names = ListDirectory(network_path, filter=\"^GCF\")\n",
    "\n",
    "    # Same arguments for all files\n",
    "    arguments = {\"sep\":\"\\t\",\n",
    "            \"header\":None,\n",
    "            \"usecols\":[1,2,3,4,8],\n",
    "            \"index_col\":None,\n",
    "            \"names\":[\"TF\",\"TG\",\"STATUS\",\"ORG_REF\", \"TU_UNIT\"]}\n",
    "\n",
    "    for net in network_file_names:\n",
    "    \n",
    "        real_path = os.path.join(network_path, net)\n",
    "        plain_graph = LoadParserNet(real_path, **arguments)\n",
    "    \n",
    "        # Getting the inferred interactions and the known interactions\n",
    "        New_network, Known_network = FilterNetworks(plain_graph)\n",
    "    \n",
    "        # Getting the contingency table of the observed values of the inferred network and the network used\n",
    "        # as a reference\n",
    "        Interactions_new = set((New_network[[\"TF\",\"TG\"]].apply(\" | \".join, axis=1)))\n",
    "        Interactions_known = set((Known_network[[\"TF\",\"TG\"]].apply(\" | \".join, axis=1)))\n",
    "    \n",
    "        Known_versus_inferred_metrics = BinaryMetrics(Interactions_known, Interactions_new)\n",
    "    \n",
    "        # Getting contingency table and expected values of random networks based on the inferred network\n",
    "        contingency = GetContingencyTable(New_network, 10000)\n",
    "        probabilities = GetExpectedProbability(contingency, 1)\n",
    "    \n",
    "        # Doing the test chi and G for goodness of fit\n",
    "    \n",
    "        Observed = Known_versus_inferred_metrics.values.reshape(-1,)\n",
    "        Expected = (probabilities * Observed.sum()).values.reshape(-1,)\n",
    "        \n",
    "        # G-test directly\n",
    "        G_d, p_value_G_d = stats.power_divergence(Observed, Expected, lambda_ = 0)\n",
    "        \n",
    "        print(\"Tests:\")\n",
    "        print(f\"\\tGd:{G_d}; p:{p_value_G_d}\")\n",
    "        \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "674b1d1ebab951aa59e675edb56ff5a7d1578544e7152a805f0968cf808183d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
